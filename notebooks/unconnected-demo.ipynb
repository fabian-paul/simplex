{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyemma\n",
    "import pyemma.datasets\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 The connectivity problem in Markov state models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When estimating conventional Markov state models from a set of many short trajectories, one is faced with the problem of finding the \"connected set\" or \"ergodic set\". This is the set of Markov states for which a stationary distribution can be computed. It consits of all the Markov states that can be exited and entered an unlimited number of times when following transition that have non-zero probability in the transtion matrix. \n",
    "\n",
    "Due to ubiquitous barrier recrossing (also called projection error) it is unsually not possible to decide if a given transition probability exactly zero or non-zero. This renders the identification of the connected set difficult. \n",
    "While this is typically not a problem when analysing a single long trajectory, a set of short trajectories may contain a high number of potentially absorbing states (that are never exited). In the latter setting, proper identification of these absorbing states is indispensable to compute correct estimates of free energ differences and kinetics.\n",
    "\n",
    "Here I demonstrate the problem with a toy model and propose two methods for its solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start, by producing some data that is by construction useless for the estimation of an MSM.\n",
    "I simulate a couple of short trajectories in the two wells of a double-well toy energy model and prevent any well-to-well transtion from happing by intterupting the simulation before any such transition is about to take place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pyemma.datasets.load_2well_discrete()\n",
    "fel = -np.log(data.msm.stationary_distribution)\n",
    "plt.plot(fel)\n",
    "plt.ylabel('energy')\n",
    "plt.xlabel('x')\n",
    "#plt.plot([48, 48], [2, 25], 'r', label='stop here!')\n",
    "#plt.plot([52, 52], [2, 25], 'r', label='stop there!')\n",
    "plt.annotate('interrupt here', xy=(48, fel[48]), xytext=(48-18, fel[48]+1), arrowprops=dict(facecolor='red'))\n",
    "plt.annotate('interrupt here', xy=(52, fel[52]), xytext=(52+5, fel[52]+1), arrowprops=dict(facecolor='red'))\n",
    "plt.ylim((3, 10))\n",
    "plt.xlim((20, 80))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the example more realistic, I add some uncorrelated noise to the trajectories.\n",
    "In a real molecular system this noise could originate from an uncorrelated (orthogonal) degree of freedom whose amplitude that was insufficiently suppressed by the non-ideal choice of features and dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulating non-connected data\n",
    "trajs1 = [ data.generate_traj(10000, start=30, stop=48).astype(float) for _ in range(4) ]\n",
    "trajs2 = [ data.generate_traj(10000, start=70, stop=52).astype(float) for _ in range(2) ]\n",
    "trajs = trajs1 + trajs2\n",
    "trajs = [ t + 3*np.random.randn(len(t)) for t in trajs ] # add some noise to model a second,\n",
    "# non-metastable dimension that is not completely orthogonal to the x-coordinate of the double-well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trajs[0])\n",
    "plt.plot(trajs[-1])\n",
    "plt.xlabel('time / steps')\n",
    "plt.ylabel('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I proceed with *k*-means clustering and state of the art MSM estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use some default algorithm\n",
    "kmeans = pyemma.coordinates.cluster_kmeans(data=trajs, k=101, fixed_seed=True)\n",
    "dtrajs = kmeans.dtrajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumlength = sum([len(d) for d in dtrajs])\n",
    "print('commulative length of all data is', cumlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the implied time scales plot for the MSM\n",
    "its = pyemma.msm.its(dtrajs)\n",
    "pyemma.plots.plot_implied_timescales(its)\n",
    "plt.plot([0, its.lagtimes[-1]], [cumlength, cumlength], 'd-', color='black', label='data length') # total data\n",
    "true_its = data.msm.timescales()[0]\n",
    "plt.plot([0, its.lagtimes[-1]], [true_its, true_its], 'd-',  color='red', label='true value') \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently there is aprocess that is much slower than the total length of the simulations data.\n",
    "Does that mean that the MSM just did its magic and that we have a result? \n",
    "No, since by construction, in this example the\n",
    "relevant well-to-well transition has not been sampled!\n",
    "So the time scale is an artifact.\n",
    "One also sees that the ITS it not converging (over the years, standards have become lower and lower, so some people might call this \"convergence\" but acutually it's not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This artifact has also an influence on the free-energies (and stationary probabilities) that can be computed form an MSM. \n",
    "To see this, I plot the stationary probability of the left well as a function of MSM lag time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now monitor the convergence of the free energy \n",
    "left_well = np.where(kmeans.clustercenters < 50)[0]\n",
    "p_left = []\n",
    "for m in its.models:\n",
    "    pi_full = np.zeros(kmeans.clustercenters.shape[0])\n",
    "    pi_full[m.active_set] = m.pi\n",
    "    p_left.append(\n",
    "        pi_full[left_well].sum()\n",
    "    )\n",
    "plt.plot(its.lags, p_left, label='MSM estimate')\n",
    "plt.plot([0, its.lagtimes[-1]], [0.5, 0.5], color='black', label='true value') # true value\n",
    "plt.ylabel('P(left well)')\n",
    "plt.xlabel('lag time / steps')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we get some results but they are completely arbitrary. These values are essentially random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CK-test doesn't tell us that there is a problem with our model.\n",
    "From this CK-test we mostly learn that the system is very metastable and \n",
    "that this metastability is reproduced accross many choices of the lag time.\n",
    "But we don't learn much about the presence or absence of transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm = pyemma.msm.estimate_markov_model(dtrajs, 100)\n",
    "cktest = msm.cktest(nsets=2)\n",
    "pyemma.plots.plot_cktest(cktest);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ways to solve the connectivity problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 hidden Markov models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMM can solve the problem of spurious connectivty using the additional layer of stochstic modelling that is built into the definition of an HMM. In HMMs, the trajectory is modelled as a sequence of transitions in some hidden space plus instantaneous emissions into the observed space. A state-to-state transition in the observed space does not need to correspond to a transition in the hidden space. It could just be that the system remains in the same hidden space but two successive \"emissions\" into the observed space just happen to fall into two different observed states.\n",
    "\n",
    "In principle, HMMs can deconvolute the simulation data into a) the \"actual\" transitions in the hidden space and b) a map between that hidden space and the observed space that can explain the the \"overlap\" of hidden states when viewed from the observed space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = pyemma.msm.estimate_hidden_markov_model(dtrajs, lag=10, nstates=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm.count_matrix_EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HMM tells us that the number of transtions between the *hidden* states is around 10^-10 which is close to the numerical procision of double precision numbers. This points towards the fact that these transitons might actually\n",
    "not be there.\n",
    "\n",
    "In practice, the ability of HMM to identify this probelm can depend on many parameters like the lag-time and the clustering (I suspect that one needs to have more than one cluster center per hidden state to be able to indentify connectivity issues with HMMs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm.timescales()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still the HMM sometimes reports an artifactual time scale and there is not good way of telling whether this value is\n",
    "and artifact or not, without prior knowledge (and without looking at `count_matrix_EM`).\n",
    "The behavior depends on the clustering and on the lag time. Sometimes an artifactual time scale is reported and sometimes not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 core set Markov models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In core set MSM one works with a relatively low number of states (cores). Typically, these cores are metastable on timescales that are comparable with the lag time of the MSM. In contrast to normal MSMs, the conformational space is not fully partitioned into states. Conformations, that can not unambigously assigned to a metastable core, stay \"unassigned\". In core set MSM transitions have to be counted differently than in normal MSMs. Only when a trajectory goes form one core to a different core, this is treated as a transition. Transitions between a core and the unassigned area that surrounds the core are not counted.\n",
    "\n",
    "One of the most important prequisites for core set MSMs is a good definition of cores. Luckily, many methods like TICA or VAMP have been developed to detect order parameters for the slowly-autocorrelated dynamic processes. Once the order parameters have been found, it's only a small step to a good definition of metastable states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to build the core MSM directy on the TICA space without going through the procedure of builing a normal MSM\n",
    "as an intermediate step. The advantages of this approach will become clearer later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a molecular system we would start the analysis by selecting some features and doing TICA (or VAMP).\n",
    "# Since the example here is 1-D, I just define some Gaussians on that 1-D axis and user them as features.\n",
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "coordinates = []\n",
    "for traj in trajs:\n",
    "    x = traj\n",
    "    coordinates.append(\n",
    "        np.array(\n",
    "            [gaussian(x, 20, 5), gaussian(x, 25, 5),\n",
    "             gaussian(x, 30, 5), gaussian(x, 35, 5),\n",
    "             gaussian(x, 40, 5), gaussian(x, 45, 5),\n",
    "             gaussian(x, 50, 5), gaussian(x, 55, 5),\n",
    "             gaussian(x, 60, 5), gaussian(x, 65, 5),\n",
    "             gaussian(x, 70, 5)]).T\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tica = pyemma.coordinates.tica(data=coordinates, lag=100)\n",
    "tics = tica.get_output(dimensions=np.arange(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One sees in the plot below that the first TIC is a good order parameter that separates the two minima (which is not really a hard problem in this 1-D example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tic in tics:\n",
    "    plt.plot(tic);\n",
    "plt.xlabel('time / steps')\n",
    "plt.ylabel('IC1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.concatenate(tics), bins=50);\n",
    "plt.xlabel('IC1')\n",
    "plt.ylabel('counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TICA eigenfunctions (together with their respective eigenvalues) can be used to define a so-called kinetic map, which is a coordinate system in which distances are related to the time the molecular system needs to change conformations. [#Noe:JChemTheoryComput:15] The most distant points on the kinetic map correspond to conformations that interconvert the least frequently. For metastable systems, it was observed that most conformations tend to cluster near the N most distant points in the N-dimensional space defined by the kinetic map. [#Weber:ZIB:04] This observation is the motivation of the inner simplex sub-algorithm of the PCCA algorithm. [#Weber:ZIB:02]\n",
    "\n",
    "### The inner-simplex sub-algorithm of PCCA\n",
    "The inner-simplex algorithm approximately finds the N most distant points in the N-dimensional space spanned by the dominant eigenfunctions. [#Weber:ZIB:02] The first eigenfunction of the transfer operator is a constant function, which we disregard for computational efficiency. This leaves all distances unchanged. We therefore seek for the N most distant points in a (N-1) dimensional space which is equivalent to finding the vertices of an N-dimensional simplex.\n",
    "\n",
    "In the initialization stage of the inner simplex algorithm, we identify the pair of most distant points. For a data set consisting of very large number of points $(>10^{6})$, this becomes computationally infeasible when using only pairwise comparisons. We therefore determine the most distant pair heuristically. To this, we first determine all points that lie on the hyper-surface of the axes-parallel bounding box of all data points. Among this subset, which can not contain more than $2\\cdot N-2$ points, we pick the most distant pair $(\\mathbf{v}_{1},\\,\\mathbf{v}_{2})$. These two points are the first and second of totally N vertices.\n",
    "\n",
    "In the remaining stages of the algorithm, we follow the procedure from reference [#Weber:ZIB:02]. In stage two, for every point $\\mathbf{x}$, we determine the distance to the line segment $[\\mathbf{v}_{1},\\,\\mathbf{v}_{2}]$ and select the point with the largest distance as the third vertex $\\mathbf{v}_{3}$. In the remaining stages, we proceed analogously in higher dimensions and compute for every point the distance to the affine subspace spanned by the already found vertices. The point with maximum distance is added to the set of vertices. This algorithm terminates when N vertices have been found, since the affine space spanned by all N vertices is equal to the space spanned by all data points.\n",
    "\n",
    "The following example uses the inner_simplex algorithm, that is not yet part of PyEmma and which I have \n",
    "implemented here: https://github.com/fabian-paul/simplex\n",
    "\n",
    "Please contact me on Github to get access to the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we find the two most distant points in the 1-D TICA space. \n",
    "# This is trivial here but the following function implements the general N-dimensional case.\n",
    "import simplex\n",
    "vertices = simplex.find_vertices_inner_simplex(tics)\n",
    "# in general the algorithm has to do N passes over the date where N is the dimension of the TICA space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing metastable memberships\n",
    "\n",
    "In the next step, we want to label all data points according to their degree of belonging to one of the vertices. A mathematically consistent way to define this degree of belonging is to use barycentric coordinates defined with respect to the vertices $\\{\\mathbf{v}_{1},\\,\\mathbf{v}_{2},\\ldots,\\mathbf{v}_{N}\\}$. That is we seek to express the (Cartesian) coordinates of every point in TICA space $\\mathbf{x}$ as $\\mathbf{x}=\\sum_{i}^{N}m_{i}\\mathbf{v}_{i}$ where $\\sum_{i}^{N}m_{i}=1$. [#Weber:ZIB:02] If we assume that the data points form clusters near the vertices (see below), we can interpret every coefficient $m_{i}$ as the membership of the point $\\mathbf{x}$ in the metastable state $i$. A point belongs in majority to metastable state $i$, if $m_{i}\\geq\\tfrac{1}{2}$. \n",
    "\n",
    "In contrast to the *k*-means algorithm, which can also be used to partition the data points, and which is the default choice in MSM construction, [#Prinz:JChemPhys:11] the inner simplex algorithm can also find metastable states that have low frequency in the simulation data. This is important for MD data that consist of many short trajectories, because the frequency of a metastable state in the data might not be representative of the Boltzmann weight of a state. Therefore the partitioning algorithm should not be too reliant on frequencies. Furthermore, sensible memberships that reflect the degree of metastability can not be defined in such a simple manner for *k*-means clusters.\n",
    "\n",
    "After having identified the metastable states in the conformational space, we next characterize the transitions between the states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the core sets\n",
    "We define the cores as high-membership regions using the metastable memberships computed with PCCA (see section above). That is \n",
    "$$S_{i}:=\\{\\mathbf{x}(t)\\mid i=\\mathrm{argmax}_{j}m_{j}(t)\\text{ and }m_{i}(t)\\geq f\\}$$ where $f$ is some value between $\\tfrac{1}{2}$ and 1. If $f=\\tfrac{1}{2}$, two cores $S_{i}$ and $S_{j}$ $(i\\neq j)$ may share a common boundary. If $f>\\tfrac{1}{2}$, the transition regions between the cores are not assigned to any core.\n",
    "\n",
    "Note that the variant of the PCCA algorithm used in this work does not guarantee that all metastable memberships are between 0 and 1. Still, our core definition remains practical. Points with $m_{i}>1$ with respect to a metastable state $i$ are just grouped together with points with $m_{i}>f$. Negative memberships are ignored by construction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Computing the transition matrix\n",
    "The correct definition of the transition matrix $\\mathbf{T}(\\tau)$ for core-based MSMs is somehow nuanced and different algorithms have been proposed for its estimation from time series data. Here, we use the transition-based assignment (TBA) method that was proposed by Buchete et al. [#Buchete:JPhysChemB:08] The main advantage of this method over the methods from Sch√ºtte et al. [#Schutte:JChemPhys:11, #Schuette:EurPhysJSpecTop:12] is that it guarantees that the elements of the resulting transition matrix are probabilities and that its eigenvalues are not larger than one. These properties will be essential for MSM validation. Transition matrix estimation with the TBA method consists of three steps. \n",
    "\n",
    "In the first step, we compute metastable memberships $\\mathbf{m}(t)=[m_{1}(t),\\,\\ldots,\\,m_{N}(t)]^{\\top}$ with respect to all metastable states for all conformations. \n",
    "\n",
    "In the second step, we assign every conformation to a core, if possible. That is, we construct a time series of core labels $\\{s(t)\\}_{t}$ where $s(t)=i$ if and only if $\\mathbf{x}(t)\\in S_{i}$. Labels $s(t)$ for the remaining conformations that are not part of a core are determined based on the history of visited cores, by splitting transitions at the midpoint. More precisely, for every time step $t$ we find the most recent valid core label $s(t_{-})$ from the past $t_{-}<t$ and the most proximate valid core label $s(t_{+})$ in the future $t_{+}>t$. Then we set $s(t):=s(t_{-})$ if $t-t_{-}<t_{+}-t$ or $s(t):=s(t_{+})$ otherwise. [#Buchete:JPhysChemB:08] The initial and final time steps of a trajectory may stay unassigned in this procedure and we ignore them from now on. \n",
    "\n",
    "In the third step, the transition matrix $\\mathbf{T}(\\tau)$ is estimated form the time series of core labels $\\{s(t)\\}_{t}$ using standard methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) comute core assignments\n",
    "ctrajs = simplex.core_assignments(tics, vertices=vertices, f=0.65, d=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next plot shows the core label over time for all trajectories. Still, the trajectories show transitions between the two cores which we know here to be artifats. This problem is addressed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show core-to-core trajectories\n",
    "for c in ctrajs:\n",
    "    plt.plot(np.where(c>=0, c, np.nan))\n",
    "plt.ylim((-0.1,1.1))\n",
    "# sometimes there are some recorssing events left, despite the introduction of cores \n",
    "plt.xlabel('time / step')\n",
    "plt.ylabel('core index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we were looking for metastable states, we can be almost sure that the fast transitons, where the trajectory switches form one core to another and then immediately returns are due to an imperfect assignment of conformations to cores. Fast switching of cores is incompatible with the metastable nature of the cores.\n",
    "Therefore we can safely delete such fast switching events from the trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) We filter out very short visits to core. \n",
    "# Technically we relabel the corresponding trajectory pieces as 'unassigned'.\n",
    "# In a later step, we could re-assign these peices to a core, if we have to.\n",
    "ctrajs_metastable = simplex.filter_out_short_core_visits(ctrajs, cutoff=10) \n",
    "# usually a small life time cutoff is enough. This number should not be larger than the lag time.\n",
    "# Here I take 1/10 th of the TICA lag time.\n",
    "for c in ctrajs_metastable:\n",
    "    plt.plot(np.where(c>=0, c, np.nan))\n",
    "plt.ylim((-0.1,1.1))\n",
    "plt.xlabel('time / step')\n",
    "plt.ylabel('core index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed no artifactual transition remains. This is confirmed when we compute the count matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) now that we are more or less sure about the discretization quality, compute count matrices.\n",
    "simplex.milestoning_count_matrix(ctrajs_metastable, lag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to the HMM count matrix (state indiced might be switched):\n",
    "hmm.count_matrix.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Future work\n",
    "In future work I will combinine TICA and HMMs in one joint stochastically optimal estimator. That estimator should be ideal for identifying connectivitiy problems by combinding the strength of good order parameters (that are found by the TICA part) and the strenght of HMM that allows to decouple the observed space from hidden space.\n",
    "\n",
    "Core set MSM have the disadvantage that the user needs to select a cut-off for the core size. Even though the value of the cut-off is approximately universal (a cutoff of 0.55 to 0.75 on the memberships should work is most situations), it would be better, if there were no user-specified parameter at all. HMMs only need to parameters: the number of states and the lag time and are therefore a good starting point for the development of better estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
